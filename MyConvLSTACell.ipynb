{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MyConvLSTACell.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNTLwy9W9CXvJj1rgOdXgkM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vyE7iCyjNRVy"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class MyConvLSTACell(nn.Module):\n","    def __init__(self, input_size, memory_size, c_cam_classes=100, kernel_size=3,\n","                 stride=1, padding=1, zero_init=False):\n","        super(MyConvLSTACell, self).__init__()\n","        self.input_size = input_size\n","        self.memory_size = memory_size\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.c_classifier = nn.Linear(memory_size, c_cam_classes, bias=False)\n","        self.coupling_fc = nn.Linear(memory_size, c_cam_classes, bias=False)\n","        self.avgpool = nn.AvgPool2d(7)\n","\n","        # Attention params\n","\n","        self.conv_i_s = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_i_cam = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n","\n","        self.conv_f_s = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_f_cam = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n","\n","        self.conv_a_s = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_a_cam = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n","\n","        self.conv_o_s = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_o_cam = nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n","\n","        if zero_init:\n","            torch.nn.init.constant(self.conv_i_s.weight, 0)\n","            torch.nn.init.constant(self.conv_i_s.bias, 0)\n","            torch.nn.init.constant(self.conv_i_cam.weight, 0)\n","\n","            torch.nn.init.constant(self.conv_f_s.weight, 0)\n","            torch.nn.init.constant(self.conv_f_s.bias, 0)\n","            torch.nn.init.constant(self.conv_f_cam.weight, 0)\n","\n","            torch.nn.init.constant(self.conv_a_s.weight, 0)\n","            torch.nn.init.constant(self.conv_a_s.bias, 0)\n","\n","            torch.nn.init.constant(self.conv_o_s.weight, 0)\n","            torch.nn.init.constant(self.conv_o_s.bias, 0)\n","            torch.nn.init.constant(self.conv_o_cam.weight, 0)\n","        else:\n","            torch.nn.init.xavier_normal(self.conv_i_s.weight)\n","            torch.nn.init.constant(self.conv_i_s.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_i_cam.weight)\n","\n","            torch.nn.init.xavier_normal(self.conv_f_s.weight)\n","            torch.nn.init.constant(self.conv_f_s.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_f_cam.weight)\n","\n","            torch.nn.init.xavier_normal(self.conv_a_s.weight)\n","            torch.nn.init.constant(self.conv_a_s.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_a_cam.weight)\n","\n","            torch.nn.init.xavier_normal(self.conv_o_s.weight)\n","            torch.nn.init.constant(self.conv_o_s.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_o_cam.weight)\n","\n","        # Memory params\n","\n","        self.conv_i_x = nn.Conv2d(input_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_i_c = nn.Conv2d(memory_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding,\n","                                  bias=False)\n","\n","        self.conv_f_x = nn.Conv2d(input_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_f_c = nn.Conv2d(memory_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding,\n","                                  bias=False)\n","\n","        self.conv_c_x = nn.Conv2d(input_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_c_c = nn.Conv2d(memory_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding,\n","                                  bias=False)\n","\n","        self.conv_o_x = nn.Conv2d(input_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_o_c = nn.Conv2d(memory_size, memory_size, kernel_size=kernel_size, stride=stride, padding=padding,\n","                                  bias=False)\n","\n","        if zero_init:\n","            torch.nn.init.constant(self.conv_i_x.weight, 0)\n","            torch.nn.init.constant(self.conv_i_x.bias, 0)\n","            torch.nn.init.constant(self.conv_i_c.weight, 0)\n","\n","            torch.nn.init.constant(self.conv_f_x.weight, 0)\n","            torch.nn.init.constant(self.conv_f_x.bias, 0)\n","            torch.nn.init.constant(self.conv_f_c.weight, 0)\n","\n","            torch.nn.init.constant(self.conv_c_x.weight, 0)\n","            torch.nn.init.constant(self.conv_c_x.bias, 0)\n","            torch.nn.init.constant(self.conv_c_c.weight, 0)\n","\n","            torch.nn.init.constant(self.conv_o_x.weight, 0)\n","            torch.nn.init.constant(self.conv_o_x.bias, 0)\n","            torch.nn.init.constant(self.conv_o_c.weight, 0)\n","        else:\n","            torch.nn.init.xavier_normal(self.conv_i_x.weight)\n","            torch.nn.init.constant(self.conv_i_x.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_i_c.weight)\n","\n","            torch.nn.init.xavier_normal(self.conv_f_x.weight)\n","            torch.nn.init.constant(self.conv_f_x.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_f_c.weight)\n","\n","            torch.nn.init.xavier_normal(self.conv_c_x.weight)\n","            torch.nn.init.constant(self.conv_c_x.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_c_c.weight)\n","\n","            torch.nn.init.xavier_normal(self.conv_o_x.weight)\n","            torch.nn.init.constant(self.conv_o_x.bias, 0)\n","            torch.nn.init.xavier_normal(self.conv_o_c.weight)\n","\n","    def forward(self, x, cam, state_att, state_inp, x_flow_i=0, x_flow_f=0, x_flow_c=0, x_flow_o=0):\n","        # state_att = [a, s]\n","        # state_inp = [atanh(c), o]\n","\n","        a_t_1 = state_att[0]\n","        s_t_1 = state_att[1]\n","\n","        c_t_1 = F.tanh(state_inp[0])\n","        o_t_1 = state_inp[1]\n","\n","        # Attention recurrence\n","\n","        i_s = F.sigmoid(self.conv_i_s(s_t_1) + self.conv_i_cam(cam))\n","        f_s = F.sigmoid(self.conv_f_s(s_t_1) + self.conv_f_cam(cam))\n","        o_s = F.sigmoid(self.conv_o_s(s_t_1) + self.conv_o_cam(cam))\n","        a_tilde = F.tanh(self.conv_a_s(s_t_1) + self.conv_a_cam(cam))\n","        a = (f_s * a_t_1) + (i_s * a_tilde)\n","        s = o_s * F.tanh(a)\n","        u = s * cam  # hidden state + cam\n","\n","        u = F.softmax(u.view(u.size(0), -1), 1)\n","        u = u.view(u.size(0), 1, 7, 7)\n","\n","        x_att = x * u.expand_as(x)\n","\n","        i_x = F.sigmoid(self.conv_i_c(o_t_1 * c_t_1) + self.conv_i_x(x_att) + x_flow_i)\n","        f_x = F.sigmoid(self.conv_f_c(o_t_1 * c_t_1) + self.conv_f_x(x_att) + x_flow_f)\n","        c_tilde = F.tanh(self.conv_c_c(o_t_1 * c_t_1) + self.conv_c_x(x_att) + x_flow_c)\n","        c = (f_x * state_inp[0]) + (i_x * c_tilde)\n","\n","        c_vec = self.avgpool(c).view(c.size(0), -1)\n","        c_logits = self.c_classifier(c_vec) + self.coupling_fc(self.avgpool(x_att).view(x_att.size(0), -1))\n","        c_probs, c_idxs = c_logits.sort(1, True)\n","        c_class_idx = c_idxs[:, 0]\n","        c_cam = self.c_classifier.weight[c_class_idx].unsqueeze(2).unsqueeze(2) * c\n","        o_x = F.sigmoid(self.conv_o_x(o_t_1 * c_t_1) + self.conv_o_c(c_cam)) \n","\n","        state_att = [a, s]\n","        state_inp = [c, o_x]\n","        return state_att, state_inp"],"execution_count":null,"outputs":[]}]}