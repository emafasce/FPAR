{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"makeDatasetRGBSelection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNPYRZ8CnmskyA8OHhjjM7O"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9VcPK2C0kIql"},"source":["import os\r\n","import torch\r\n","from torch.utils.data import Dataset\r\n","from PIL import Image\r\n","import numpy as np\r\n","import glob\r\n","import random\r\n","from google.colab import drive\r\n","from PIL import Image\r\n","from torch.nn import functional as F\r\n","import heapq\r\n","\r\n","def gen_split(root_dir, stackSize, train, frameType):\r\n","    Dataset = []\r\n","    Labels = []\r\n","    NumFrames = []\r\n","    if train==True:\r\n","      list_folder=['S1', 'S3', 'S4']\r\n","    elif train==False:\r\n","      list_folder=['S2']\r\n","    for dir_user in list_folder: #S1,S2,S3,S4\r\n","      class_id=0\r\n","      dir = os.path.join(root_dir, dir_user)\r\n","      for target in sorted(os.listdir(dir)): #action1, action2\r\n","        dir1 = os.path.join(dir, target)\r\n","        insts = sorted(os.listdir(dir1))\r\n","        if insts != []:\r\n","          i=0\r\n","          for inst in insts:\r\n","            if frameType=='r':\r\n","              inst_dir = os.path.join(dir1, inst, 'rgb')\r\n","            elif frameType=='m':\r\n","              inst_dir = os.path.join(dir1, inst, 'mmaps')\r\n","            numFrames = len(glob.glob1(inst_dir, '*.png'))\r\n","            if numFrames >= stackSize or inst_dir=='/content/gdrive/My Drive/Project FPAR2/ego-rnn/GTEA61/processed_frames2/S3/stir_spoon,cup/2/mmaps' or inst_dir=='/content/gdrive/My Drive/Project FPAR2/ego-rnn/GTEA61/processed_frames2/S4/pour_sugar,spoon,cup/1/mmaps':\r\n","              Dataset.append(inst_dir)\r\n","              Labels.append(class_id)\r\n","              NumFrames.append(numFrames)\r\n","            else:\r\n","              i+=1\r\n","          if len(insts)==i:\r\n","            print(f'This should not be considered! Frametype: {frametype}')\r\n","            print(dir1)\r\n","        class_id+=1\r\n","    return Dataset, Labels, NumFrames   \r\n","\r\n","class makeDataset(Dataset):\r\n","\r\n","    def __init__(self, root_dir, spatial_transform=None, seqLen=20,\r\n","                 train=True, mulSeg=False, numSeg=1, fmt='.png', frameType='m'):\r\n","\r\n","        self.frameType=frameType\r\n","        self.root_dir=root_dir\r\n","        self.images, self.labels, self.numFrames = gen_split(root_dir, 5, train, frameType)\r\n","        self.spatial_transform = spatial_transform\r\n","        self.train = train\r\n","        self.mulSeg = mulSeg\r\n","        self.numSeg = numSeg\r\n","        self.seqLen = seqLen\r\n","        self.fmt = fmt\r\n","\r\n","    def __len__(self):\r\n","        return len(self.images)\r\n","\r\n","    def __getitem__(self, idx):\r\n","        vid_name = self.images[idx]\r\n","        label = self.labels[idx]\r\n","        numFrame = self.numFrames[idx]\r\n","        inpSeq = []\r\n","        black=0\r\n","        tot=0\r\n","        back=0\r\n","        seqLen=self.seqLen\r\n","        self.spatial_transform.randomize_parameters()\r\n","        dic={}\r\n","        n=max(seqLen, numFrame-1)\r\n","\r\n","        for i in np.linspace(1, numFrame, n, endpoint=False):\r\n","        #np.linspace(1, numFrame, 1, endpoint=True):\r\n","          tot+=1\r\n","\r\n","          try:\r\n","            fl_name = vid_name + '/' + 'map' + str(int(np.floor(i))).zfill(4) + self.fmt\r\n","            img = Image.open(fl_name)\r\n","          except:\r\n","            try:\r\n","              fl_name = vid_name + '/' + 'map' + str(int(np.floor(i+1))).zfill(4) + self.fmt\r\n","              img = Image.open(fl_name)\r\n","            except:\r\n","              try:\r\n","                fl_name = vid_name + '/' + 'map' + str(int(np.floor(i-1))).zfill(4) + self.fmt\r\n","                img = Image.open(fl_name)\r\n","              except:\r\n","                try:\r\n","                  fl_name = vid_name + '/' + 'map' + str(int(np.floor(i+2))).zfill(4) + self.fmt\r\n","                  img = Image.open(fl_name)\r\n","                except:\r\n","                  try:\r\n","                    fl_name = vid_name + '/' + 'map' + str(int(np.floor(i-2))).zfill(4) + self.fmt\r\n","                    img = Image.open(fl_name)\r\n","                  except:\r\n","                    a=0\r\n","          img=self.spatial_transform(img.convert('L'))\r\n","          summ=torch.sum(img)\r\n","          dic[np.floor(i)]=summ\r\n","        #h=sorted(heapq.nlargest(seqLen, dic, key=dic.get))\r\n","        h=sorted(dic, key=dic.get, reverse=True)[:seqLen]\r\n","        h=sorted(h)\r\n","        #print(len(h))\r\n","        #print(vid_name, h)\r\n","        for i in h:\r\n","          fl_name = vid_name + '/' + 'rgb' + str(int(np.floor(i))).zfill(4) + self.fmt\r\n","          f_name=fl_name.replace('mmaps','rgb')\r\n","          img = Image.open(f_name)\r\n","          img=self.spatial_transform(img.convert('RGB'))\r\n","          inpSeq.append(img)\r\n","        if len(inpSeq)!=seqLen:\r\n","          diff=seqLen-len(inpSeq)\r\n","          for p in range(diff):\r\n","            inpSeq.append(inpSeq[-1])              \r\n","        inpSeq = torch.stack(inpSeq, 0)\r\n","        return inpSeq, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5vJNkC2MmaG","executionInfo":{"status":"ok","timestamp":1610301144734,"user_tz":-60,"elapsed":1249,"user":{"displayName":"Luca Neromoro","photoUrl":"","userId":"08197997045770955362"}},"outputId":"366b106c-2b25-4aa5-9795-c4310c54a97f"},"source":["'''\r\n","!pip install import_ipynb\r\n","import import_ipynb\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive',  force_remount=True)\r\n","%cd /content/gdrive/My Drive/Project FPAR2/ego-rnn\r\n","\r\n","from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\r\n","                                RandomHorizontalFlip)\r\n","\r\n","normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n","spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224), ToTensor(), normalize])\r\n","from torchvision.transforms import Resize\r\n","spatial_transform_mmap = Compose([Resize(256),ToTensor()])\r\n","seqLen=7\r\n","train_data_dir='./GTEA61/processed_frames2'\r\n","vid_seq_train = makeDataset(train_data_dir,\r\n","                            spatial_transform=spatial_transform, seqLen=seqLen, frameType='m', fmt='.png', train=False)\r\n","trainBatchSize=32\r\n","train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\r\n","                        shuffle=True, num_workers=4, pin_memory=True)\r\n","'''"],"execution_count":2,"outputs":[{"output_type":"stream","text":["16\n"],"name":"stdout"}]}]}
