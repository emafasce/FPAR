{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"objectAttentionModelConvLSTMVisualize.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPgD9RvYi7oiNzeTU6jDPsC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9LFT7kG2vA2l","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"error","timestamp":1609074363754,"user_tz":-60,"elapsed":3271,"user":{"displayName":"Luca Neromoro","photoUrl":"","userId":"08197997045770955362"}},"outputId":"2cabe5c4-9334-498e-bb0e-ea3d78b725a5"},"source":["import torch\n","import resnetMod\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.autograd import Variable\n","from MyConvLSTMCell import *\n","\n","\n","class attentionModel(nn.Module):\n","    def __init__(self, num_classes=61, mem_size=512):\n","        super(attentionModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.resNet = resnetMod.resnet34(True, True)\n","        self.mem_size = mem_size\n","        self.weight_softmax = self.resNet.fc.weight\n","        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc = nn.Linear(mem_size, self.num_classes)\n","        self.classifier = nn.Sequential(self.dropout, self.fc)\n","\n","    def forward(self, inputVariable, img, size_upsample):\n","        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n","                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n","        for t in range(inputVariable.size(0)):\n","\n","          logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n","          bz, nc, h, w = feature_conv.size()\n","          feature_conv = feature_conv.view(bz, nc, h*w)\n","          h_x = F.softmax(logit, dim=1).data\n","          probs, idx = h_x.sort(1, True)\n","          cam_img = torch.bmm(self.weight_softmax[idx[:, 0]].unsqueeze(1), feature_conv).squeeze(1)\n","          cam_img = F.softmax(cam_img, 1).data \n","          cam_img = cam_img.cpu().numpy()\n","          cam_img = cam_img.reshape(h, w)\n","          cam_img = cam_img - np.min(cam_img)\n","          cam_img = cam_img / np.max(cam_img)\n","          cam_img = np.uint8(255 * cam_img)\n","          output_cam = cv2.resize(cam_img, size_upsample)\n","          img = cv2.cvtColor(np.uint8(img), cv2.COLOR_RGB2BGR)\n","          heatmap = cv2.applyColorMap(output_cam, cv2.COLORMAP_JET)\n","          result = heatmap * 0.3 + img * 0.5\n","\n","        '''\n","        for t in range(inputVariable.size(0)):\n","            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n","            bz, nc, h, w = feature_conv.size()\n","            feature_conv1 = feature_conv.view(bz, nc, h*w)\n","            probs, idxs = logit.sort(1, True)\n","            class_idx = idxs[:, 0]\n","            cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n","            cam_img = F.softmax(cam, 1).data\n","            cam_img = cam_img.cpu().numpy()\n","            cam_img = cam_img.reshape(h, w)\n","            cam_img = cam_img - np.min(cam_img)\n","            cam_img = cam_img / np.max(cam_img)\n","            cam_img = np.uint8(255 * cam_img)\n","            output_cam = cv2.resize(cam_img, size_upsample)\n","            img = cv2.cvtColor(np.uint8(img), cv2.COLOR_RGB2BGR)\n","            heatmap = cv2.applyColorMap(output_cam, cv2.COLORMAP_JET)\n","            result = heatmap * 0.3 + img * 0.5\n","            print(result)\n","        '''"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ca38b89a3a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mresnetMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resnetMod'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]}]}