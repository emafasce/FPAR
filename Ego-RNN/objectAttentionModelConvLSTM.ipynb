{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"objectAttentionModelConvLSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNP4FbEu8D/laO2HDpSvc8l"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9LFT7kG2vA2l"},"source":["import torch\n","import resnetMod\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.autograd import Variable\n","from MyConvLSTMCell import *\n","\n","\n","class attentionModel(nn.Module):\n","    def __init__(self, num_classes=61, mem_size=512):\n","        super(attentionModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.resNet = resnetMod.resnet34(True, True)\n","        self.mem_size = mem_size\n","        self.weight_softmax = self.resNet.fc.weight\n","        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc = nn.Linear(mem_size, self.num_classes)\n","        self.classifier = nn.Sequential(self.dropout, self.fc)\n","\n","    def forward(self, inputVariable, cam_yes=True):\n","        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n","                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n","        for t in range(inputVariable.size(0)):\n","            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n","            bz, nc, h, w = feature_conv.size()\n","            feature_conv1 = feature_conv.view(bz, nc, h*w)\n","            probs, idxs = logit.sort(1, True)\n","            class_idx = idxs[:, 0]\n","            cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n","            attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n","            attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n","            attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n","            if cam_yes==True:\n","              state = self.lstm_cell(attentionFeat, state)\n","            else:\n","              state = self.lstm_cell(feature_conv, state)\n","        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n","        feats = self.classifier(feats1)\n","        return feats, feats1"],"execution_count":null,"outputs":[]}]}
