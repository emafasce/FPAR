{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"objectAttentionModelConvAugmentedLSTM.ipynb","provenance":[{"file_id":"10o75bnkKfkYkfAnO4XRpn4_C8AuD4VIq","timestamp":1606411206544}],"collapsed_sections":[],"authorship_tag":"ABX9TyOkXt+rO4toU4i/UFIlqHpT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9LFT7kG2vA2l"},"source":["import torch\n","import resnetMod\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.autograd import Variable\n","from MyConvAugmentedLSTMCell import *\n","\n","\n","class attentionModel(nn.Module):\n","    def __init__(self, num_classes=61, mem_size=512):\n","        super(attentionModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.resNet = resnetMod.resnet34(True, True)\n","        self.mem_size = mem_size\n","        self.weight_softmax = self.resNet.fc.weight\n","        self.lstm_cell = MyConvAugmentedLSTMCell(512, mem_size)\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc = nn.Linear(mem_size*2, self.num_classes)\n","        self.classifier = nn.Sequential(self.dropout, self.fc)\n","\n","    def forward(self, inputVariable):\n","        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n","                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n","        state_cam = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n","                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n","        for t in range(inputVariable.size(0)):\n","            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n","            bz, nc, h, w = feature_conv.size()\n","            feature_conv1 = feature_conv.view(bz, nc, h*w)\n","            probs, idxs = logit.sort(1, True)\n","\n","            #First class\n","            class_idx = idxs[:, 0]\n","            cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n","            attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n","            attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n","            attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n","\n","            #Second class\n","            class_idx_1 = idxs[:, 1]\n","            cam = torch.bmm(self.weight_softmax[class_idx_1].unsqueeze(1), feature_conv1)\n","            attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n","            attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n","            attentionFeat_1 = feature_convNBN * attentionMAP.expand_as(feature_conv)\n","            #state, state_cam = self.lstm_cell(feature_conv, attentionFeat, state, state_cam)\n","            state, state_cam = self.lstm_cell(attentionFeat_1, attentionFeat, state, state_cam)\n","            \n","        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n","        feats1_cam = self.avgpool(state_cam[1]).view(state_cam[1].size(0), -1)\n","        feats = self.classifier(torch.cat([feats1,feats1_cam], dim=1))\n","        return feats, feats1"],"execution_count":null,"outputs":[]}]}
